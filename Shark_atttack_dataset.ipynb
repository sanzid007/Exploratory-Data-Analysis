{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["fHfdxHX32JHl","JR9Zopo25BV0","F5hzLk5Q8uTQ","tJAExohTG3ee","c_9xxOCqImON","20UJGovA-o_d","GAppFaL-P6tB","vMLs1eoMbTcH","k_ZSM-_uVzea","53y6EaVfbZo-","_jYSq3-NWr4q","9frir5bzbZ9m","VH4oH9SKZO4l","L04340g5tJ_N","fOeN8BGKqxTu","tC8sJ9AG5cGv","0N7AuPkqwIdQ","romQevJ7lnCS","Qq5R2uWMRCYv","ExuwRNt-RJSf"],"authorship_tag":"ABX9TyP0u3qxNnosZbg9Aes+nD/e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Dataset Name:** Shark Attack\n","# **Dataset Source:** https://mavenanalytics.io/data-playground?search=shark\n","# **Dataset Description**\n","# This is a dataset of Shark attacks reported over the past 100 years, including location (country & city), activity, injury type, victim info (name, gender, age), shark species, etc.The dataset consists of 22 fields & 25614 records. There are both Numerical and Categorical data in this dataset. Most of the data are Categorical. The remaining Numerical Data are also in object form which need preprocessing to convert them into integer. This dataset was posted on 2020.\n","\n"],"metadata":{"id":"fHfdxHX32JHl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpAp6jstybuQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714678033170,"user_tz":-360,"elapsed":23019,"user":{"displayName":"Sanzid Hossain (Eyasin)","userId":"06051275045476070532"}},"outputId":"ff7d03cb-36b7-4bc5-be3d-91c3e2c097e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import copy\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import roc_auc_score, roc_curve\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.impute import SimpleImputer\n","from sklearn.svm import SVC\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from collections import Counter\n","from datetime import datetime"],"metadata":{"id":"_i3JORMN4N4U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Load the Dataset**"],"metadata":{"id":"JR9Zopo25BV0"}},{"cell_type":"code","source":["atk = pd.read_csv(\"/content/drive/MyDrive/Datasets/shark_attacks.csv\", encoding=\"latin-1\")\n","backup_atk = copy.deepcopy(atk)\n"],"metadata":{"id":"J74qfVmB44s7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Overview of Dataset**"],"metadata":{"id":"F5hzLk5Q8uTQ"}},{"cell_type":"code","source":["atk.head()\n","atk.shape\n","atk.info()\n","atk.describe()"],"metadata":{"id":"ar2vCZWR8z0f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Deleting unnecessary columns**"],"metadata":{"id":"tJAExohTG3ee"}},{"cell_type":"code","source":["# deleting columns\n","column_to_delete = {'Case Number', 'Investigator or Source', 'pdf', 'href', 'href formula','Case Number', 'original order', 'Area', 'Case Number.1', 'Case Number.2'}\n","for x in column_to_delete:\n","  if x in atk.columns:\n","      atk.drop(x, axis=1, inplace=True)\n","      print(f\"Column '{x}' deleted successfully.\")\n","  else:\n","      print(f\"Column '{x}' not found.\")\n","\n","\n","# Save the modified DataFrame to a new CSV file\n","atk.to_csv('sharkAttacks.csv', index=False)"],"metadata":{"id":"6fkrPfA_E0YB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Merging identical columns**"],"metadata":{"id":"c_9xxOCqImON"}},{"cell_type":"code","source":["atk = atk.groupby(level=0, axis=1).first()\n","\n","# Save the merged DataFrame to a new CSV file\n","atk.to_csv('shark_attacks.csv', index=False)"],"metadata":{"id":"VN9mI07JIl69"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Label Encoding**"],"metadata":{"id":"20UJGovA-o_d"}},{"cell_type":"code","source":["# Label encoding to get numeric value from Sex and Fatal column\n","sex_label_encoder = LabelEncoder()\n","atk['sex_numeric'] = sex_label_encoder.fit_transform(atk['Sex'])\n","\n","fatal_label_encoder = LabelEncoder()\n","atk['fatal_numeric'] = fatal_label_encoder.fit_transform(atk['Fatal'])"],"metadata":{"id":"ZBjjTNqH-s2G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Data Preprocessing**"],"metadata":{"id":"GAppFaL-P6tB"}},{"cell_type":"code","source":["# Renaming faulty column names\n","\n","atk.rename(columns={'Sex ': 'Sex'}, inplace=True)\n","atk.rename(columns={'Species ': 'Species'}, inplace=True)\n","atk.rename(columns={'Fatal (Y/N)': 'Fatal'}, inplace=True)\n","\n","atk.columns"],"metadata":{"id":"f5j_C-4D6-V8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Converting Age data type from object to int\n","\n","# drop rows with non-integer values\n","atk = atk.dropna(subset=['Age'])\n","\n","# convert non-integer values to NaN\n","atk['Age'] = pd.to_numeric(atk['Age'], errors='coerce')\n","\n","# impute missing values\n","atk['Age'].fillna(atk['Age'].mean(), inplace=True)\n","\n","# conversion to int\n","atk['Age'] = atk['Age'].astype(int)"],"metadata":{"id":"R5GT3SG7Iblw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# converting year data type from float to int\n","\n","# drop rows with non-integer values\n","atk = atk.dropna(subset=['Year'])\n","\n","# convert non-integer values to NaN\n","atk['Year'] = pd.to_numeric(atk['Year'], errors='coerce')\n","\n","# impute missing values\n","atk['Year'].fillna(atk['Year'].mean(), inplace=True)\n","\n","# conversion to int\n","atk['Year'] = atk['Year'].astype(int)\n","atk.dtypes"],"metadata":{"id":"OG5-dVhxKCC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocessing DATE\n","def date(date):\n","  months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n","  order = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n","\n","  date = str(date)\n","  if (len(date) == 11 and date[2] == '-'):\n","    for i in range(len(months)):\n","      date = date.replace(months[i], order[i])    # replacing month name with its order number\n","    return date\n","  else:\n","    return np.nan"],"metadata":{"id":"oLul0UGJP-wW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocessing YEAR\n","def year(year):\n","    if year > 1800:\n","      return year\n","    else:\n","      return np.nan\n"],"metadata":{"id":"6I9z0yYHQwU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocessing SEX\n","def sex(sex):\n","  if sex == 'M' or sex == 'F':\n","    return sex\n","  else:\n","    return np.nan"],"metadata":{"id":"jA8tCCqcQzBn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocessing AGE\n","def age(age):\n","  try:\n","    age = int(age)\n","  except ValueError:\n","    age = 0\n","\n","  if age > 0 and age <= 100:\n","    return age\n","  else:\n","    return np.nan"],"metadata":{"id":"cREDDFq3Q8GX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preprocessing FATAL\n","def fatal(fatal):\n","  if fatal == 'N' or fatal == 'Y':\n","    return fatal\n","  else:\n","    return np.nan"],"metadata":{"id":"ZjhYk5uEQ-y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calling the preprocessing functions\n","\n","#atk['Date'] = atk['Date'].apply(date)\n","atk['Year'] = atk['Year'].apply(year)\n","atk['Sex'] = atk['Sex'].apply(sex)\n","atk['Age'].fillna(0, inplace=True)\n","atk['Age'] = atk['Age'].apply(age)\n","atk['Fatal'] = atk['Fatal'].apply(fatal)\n","#atk.describe()"],"metadata":{"id":"fA3Ip6EDRext"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Age**"],"metadata":{"id":"vMLs1eoMbTcH"}},{"cell_type":"code","source":["plt.hist(atk['Age'], bins=10, color='skyblue', edgecolor='black')\n","\n","# Add labels and title\n","plt.xlabel('Age')\n","plt.ylabel('Count')\n","plt.title('Histogram')\n","\n","# Show plot\n","plt.show()"],"metadata":{"id":"SaT0_yxnX0no"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis Based on Fataliity**\n"],"metadata":{"id":"k_ZSM-_uVzea"}},{"cell_type":"code","source":["fatal_vals = atk['Fatal'].value_counts().tolist()\n","\n","f, ax = plt.subplots(figsize=(5, 5))\n","\n","labels = ['Not Fatal', 'Fatal']\n","colors = ['green', 'red']\n","\n","plt.pie(fatal_vals, labels=labels, colors=colors,\n","        autopct='%1.1f%%', startangle=90)\n","\n","axis = plt.axis('equal')"],"metadata":{"id":"n0244f_6bZZO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Shark Species**"],"metadata":{"id":"53y6EaVfbZo-"}},{"cell_type":"code","source":["from_re = [r'.*?\\bwhite\\b\\s+\\bshark\\b.*',r'.*?\\bblue\\b\\s+\\bshark\\b.*', r'.*?\\btiger\\b\\s.*',\n","           r'.*?\\bbull\\b\\s.*',r'.*?\\bshark\\b\\s+\\binvolvement\\b.*',r'.*?\\bwobbegong\\b\\s+\\bshark\\b.*',\n","           r'.*?\\bblacktip\\b\\s.*', r'.*?\\bbronze\\b\\s+\\bwhaler\\b.*', r'.*?\\bmako\\b\\s.*',r'.*?\\bnurse\\b\\s.*',\n","           r'.*?\\bhammerhead\\b\\s.*', r'.*?\\braggedtooth\\b\\s.*']\n","\n","\n","to_re = ['White shark', 'Blue shark', 'Tiger shark',\n","         'Bull shark', 'Not a shark', 'Wobbegong shark',\n","         'Blacktip shark','Bronze whaler shark', 'Mako shark',\n","         'Nurse shark', 'Hammerhead shark', 'Raggedtooth shark']\n","\n","atk.Species = atk.Species.str.lower().replace(from_re, to_re, regex=True)\n","\n","top = atk.Species.value_counts().head(7)\n","\n","sns.set(rc={'axes.facecolor':'w', 'figure.facecolor':'white'})\n","top.plot(kind='bar', figsize=(6, 4), alpha=0.9, color='skyblue', rot=45, fontsize=9)\n","plt.xlabel('Species')\n","plt.ylabel('Number of cases', fontsize=10)\n","plt.title('Top 7 most dangerous species of shark')\n","plt.grid(color='k', axis='y', alpha=0.4)\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"RThfkJ-PbZzm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Activity**"],"metadata":{"id":"_jYSq3-NWr4q"}},{"cell_type":"code","source":["prov_activity = atk[atk.Type == 'Provoked'].groupby('Activity')['Activity'].count().sort_values(ascending=False)[:10]\n","\n","fig = px.bar(prov_activity, x=prov_activity.values, y=prov_activity.index, orientation='h', labels={'index':'','x':'Attack Count'},\n","            title = 'Provoked Attacks by Activity')\n","fig.update_layout(height=500, width=800)\n","fig.show()\n","\n","atk['Species'].value_counts()\n","prov_activity.describe()\n","prov_activity.head()"],"metadata":{"id":"MlgmE7vvW0Y5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Sex**"],"metadata":{"id":"9frir5bzbZ9m"}},{"cell_type":"code","source":["sex_vals = atk['Sex'].value_counts().tolist()\n","\n","f, ax = plt.subplots(figsize=(6, 6))\n","\n","labels = ['Male', 'Female', 'Unknown', 'Not reported', 'Invalid', 'No data']\n","colors = ['blue', 'pink', 'grey', 'orange', 'red', 'black']\n","\n","plt.pie(sex_vals, labels=labels, colors=colors,\n","        autopct='%1.1f%%', startangle=90)\n","\n","axis = plt.axis('equal')"],"metadata":{"id":"WpYLrSxcbaHm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Years**"],"metadata":{"id":"VH4oH9SKZO4l"}},{"cell_type":"code","source":["# Convert 'Date' column to datetime with flexible format\n","atk['Date'] = pd.to_datetime(atk['Date'], infer_datetime_format=True, errors='coerce')\n","\n","# Drop rows with missing or incorrect dates\n","atk = atk.dropna(subset=['Date'])\n","\n","# Extract year from 'Date' column\n","atk['Year'] = atk['Date'].dt.year\n","\n","# Group data by 'Year' and count incidents\n","yearly_incidents = atk.groupby('Year').size()\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(yearly_incidents.index, yearly_incidents.values, marker='o')\n","plt.title('Shark Attack Incidents Over the Years')\n","plt.xlabel('Year')\n","plt.ylabel('Number of Incidents')\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"L0x2xH1xZWa9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Injury type**\n"],"metadata":{"id":"L04340g5tJ_N"}},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","sns.countplot(x='Injury', data=atk)\n","plt.title('Distribution of Injury Severity')\n","plt.xlabel('Injury Severity')\n","plt.ylabel('Count')\n","plt.show()"],"metadata":{"id":"l_pr9I0Ntkyq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Analysis based on Country**"],"metadata":{"id":"fOeN8BGKqxTu"}},{"cell_type":"code","source":["countryCount = atk['Country'].value_counts().reset_index()\n","countryCount.head()"],"metadata":{"id":"Yp21rY3kq5k2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = px.choropleth(data_frame = countryCount,\n","                    locations = 'Country',\n","                    color = 'count',\n","                    locationmode = 'country names',\n","                    scope = 'world',\n","                    title = 'Shark Attack around the World')\n","\n","fig.show()"],"metadata":{"id":"1arRzOGFq8Yz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(dpi=120)\n","sns.barplot(data=countryCount.head(5), y='count', x='Country', palette='Set2')\n","plt.title('Top 5 Countries with Highest number of Shark Attack cases')\n","plt.show()"],"metadata":{"id":"xKvCGBTprBQF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Bivariate Analysis on Sex and Fatality**"],"metadata":{"id":"uzX511v1lbr6"}},{"cell_type":"code","source":["biv = atk.groupby(['Sex', 'Fatal'],as_index=False).size()\n","biv = biv.sort_values(by=['size'], ascending=False)\n","biv.head()"],"metadata":{"id":"7_Hu8XyClmHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlabels=['Male Non Fatal', 'Male Fatal','Female Non Fatal','Female Fatal']\n","plt.pie(biv['size'],labels=mlabels,autopct='%1.1f%%')\n","plt.title('comparison of fatal/non fatal accidents among women and men')\n","fig.set_size_inches(12,12)\n","plt.show()"],"metadata":{"id":"UqQwyar8lwmS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Bivariate Analysis based on Species and Fatality**"],"metadata":{"id":"zCWZ23PS0s_R"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","sns.scatterplot(x=atk['Species'], y=atk['Fatal'], data=data, color='blue')\n","plt.title('Scatter plot of variable1 vs variable2')\n","plt.xlabel(str(atk['Species']))\n","plt.ylabel(str(atk['Fatal']))\n","plt.show()"],"metadata":{"id":"mC969s-_1CQx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Bivariate Analysis based on Country and Fatality**"],"metadata":{"id":"biad_9UD2fKs"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","sns.scatterplot(x=atk['Country'], y=atk['Fatal'], data=data, color='blue')\n","plt.title('Scatter plot of variable1 vs variable2')\n","plt.xlabel(str(atk['Country']))\n","plt.ylabel(str(atk['Fatal']))\n","plt.show()"],"metadata":{"id":"TMU7ixDG2kdN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Multivariate Analysis using PairPlot**"],"metadata":{"id":"tC8sJ9AG5cGv"}},{"cell_type":"code","source":["sns.pairplot(atk)\n","plt.show()"],"metadata":{"id":"izp1RhzV5kjJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **One Hot Encoding**"],"metadata":{"id":"0N7AuPkqwIdQ"}},{"cell_type":"code","source":["#print(atk.dtypes)\n","\n","# Perform one hot encoding on key features\n","columns_to_encode1 = ['Country', 'Species']\n","ohe1 = pd.get_dummies(atk, columns = columns_to_encode1)\n","\n","columns_to_encode2 = ['Country','Sex']\n","ohe2 = pd.get_dummies(atk, columns = columns_to_encode2)\n","\n","columns_to_encode3 = ['Country', 'Type']\n","ohe3 = pd.get_dummies(atk, columns = columns_to_encode3)\n","\n","# Display the encoded DataFrame\n","print(\"Encoded DataFrame:\")\n","print(ohe1)"],"metadata":{"id":"L0D0CY5MwL-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ohe2)"],"metadata":{"id":"7DRQfUPiPgos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ohe3)"],"metadata":{"id":"QQD7uCzHPkjX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Correlation and Heatmap**\n"],"metadata":{"id":"romQevJ7lnCS"}},{"cell_type":"code","source":["sns.heatmap(atk.corr(method='pearson', min_periods=1, numeric_only=True), annot = True)\n","sns.pairplot(atk)"],"metadata":{"id":"1PBWML8cXS6p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model Training**"],"metadata":{"id":"G2YzmLWvwGF_"}},{"cell_type":"markdown","source":["# Classification\n"],"metadata":{"id":"Qq5R2uWMRCYv"}},{"cell_type":"code","source":["# handle NaN values and drop them\n","atk.isnull().sum()\n","atk = atk.dropna()\n","\n","# impute missing values\n","imputer = SimpleImputer(strategy=\"mean\")\n","atk[[\"Year\", \"Age\", \"sex_numeric\"]] = imputer.fit_transform(atk[[\"Year\", \"Age\", \"sex_numeric\"]])\n","\n","X = atk[['Year', 'Age', 'sex_numeric']]  # Features\n","y = atk['Fatal']  # Target variable\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the logistic regression model\n","model = LogisticRegression()\n","\n","# Train the model on the training data\n","model.fit(X_train, y_train)\n","\n","# Make predictions on the testing data\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Display classification report\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))"],"metadata":{"id":"D7oSyHzW_qkv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Neural Network"],"metadata":{"id":"ExuwRNt-RJSf"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import accuracy_score\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from google.colab import drive\n","\n","data = pd.read_csv('/content/drive/MyDrive/Datasets/shark_attacks.csv', usecols=['Year', 'Country', 'Sex ', 'Age', 'Fatal (Y/N)'], encoding='latin1')\n","data.dropna(inplace=True)\n","\n","data = data[data['Country'].notna()]\n","data = data[data['Sex '].notna()]\n","data = data[data['Sex '].isin(['M', 'F'])]\n","data = data[data['Age'].notna()]\n","data = data[~data['Age'].str.contains(r'[a-zA-Z]|&|\\?')]\n","\n","data['Fatal (Y/N)'] = data['Fatal (Y/N)'].apply(lambda x: 1 if x == 'Y' else 0)\n","\n","label_encoder = LabelEncoder()\n","data['Country'] = label_encoder.fit_transform(data['Country'])\n","data['Sex '] = label_encoder.fit_transform(data['Sex '])\n","\n","data['Age'] = data['Age'].str.replace(r'\\D', '')\n","data['Age'] = pd.to_numeric(data['Age'], errors='coerce')\n","\n","data.dropna(subset=['Age'], inplace=True)\n","\n","X = data.drop('Fatal (Y/N)', axis=1)\n","y = data['Fatal (Y/N)']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","model = keras.Sequential([\n","    layers.Dense(64, activation='relu', input_shape=[X_train_scaled.shape[1]]),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n","\n","_, accuracy = model.evaluate(X_test_scaled, y_test)\n","print('Accuracy:', accuracy)\n","\n","y_pred_prob = model.predict(X_test_scaled)\n","\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"id":"EBCysUv1ROPM"},"execution_count":null,"outputs":[]}]}